{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweets = pd.read_json('../../data/00-raw-data/tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(raw_tweets.keys()) - 1\n",
    "tweets_l = []\n",
    "for i in range(0, n):\n",
    "    if(raw_tweets[str(i)]['lang'] == 'en'):\n",
    "        tweets_l.append(raw_tweets[str(i)]['text'])\n",
    "tweets_l = list(dict.fromkeys(tweets_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTER OUT UNWANTED CHAR\n",
    "tweets_printable = []\n",
    "\n",
    "for text in tweets_l:\n",
    "    new_text=\"\"\n",
    "    for character in text:\n",
    "        if character in string.printable:\n",
    "            new_text+=character\n",
    "    tweets_printable.append(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_clean = []\n",
    "\n",
    "for tweet in tweets_printable:\n",
    "    clean = re.sub(r\"@[A-Za-z0-9_]+\", \"\", tweet)\n",
    "    clean = re.sub(r'http\\S+', \"\", clean)\n",
    "    clean = re.sub(r'https\\S+', \"\", clean)\n",
    "    clean = re.sub(r'www\\S+', \"\", clean)\n",
    "    clean = clean.strip()\n",
    "    initial_clean.append(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_hashtags = []\n",
    "for tweet in initial_clean:\n",
    "    hashtags = re.findall(\"#([a-zA-Z0-9_]{1,50})\", tweet)\n",
    "    if hashtags:\n",
    "        tweets_hashtags.append(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [hashtag for sublist in tweets_hashtags for hashtag in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "tokenized = [nltk.tokenize.word_tokenize(tweet.lower().strip()) for tweet in flat_list]\n",
    "no_stopwords = []\n",
    "\n",
    "for tweet in tokenized:\n",
    "    for word in tweet:\n",
    "        if word not in stop:\n",
    "            no_stopwords.append(word)\n",
    "\n",
    "# ref: https://stackoverflow.com/questions/10017147/removing-a-list-of-characters-in-string\n",
    "to_remove = [\".\",\",\",\"!\",\"?\",\":\",\";\",\"_\"]\n",
    "cleaned_tweets = [tweet.translate({ord(x): '' for x in to_remove}) for tweet in no_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()   \n",
    "\n",
    "Xs  =  vectorizer.fit_transform(cleaned_tweets)   \n",
    "tweets = pd.DataFrame.from_dict(vectorizer.vocabulary_, orient='index')\n",
    "tweets.reset_index(inplace=True)\n",
    "tweets.columns = ['Word', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.replace('', np.nan, inplace=True)\n",
    "tweets.dropna(inplace=True)\n",
    "tweets.sort_values('Count', ascending=False, inplace=True)\n",
    "tweets.reset_index(inplace=True)\n",
    "\n",
    "# remove incomplete / nonsense words\n",
    "to_drop = [21, 23, 32, 40, 43, 48, 71, 119, 171, 178 , 208, 213, 217, 257, 260]\n",
    "tweets.drop(to_drop,axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('./../../data/01-modified-data/Tweets_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employment and Wages (BLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../../data/00-raw-data/wages_(by_occupation_may_2021).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['OCC_TITLE', 'O_GROUP', 'TOT_EMP', 'EMP_PRSE', 'A_MEAN', 'MEAN_PRSE']]\n",
    "df = df.iloc[1:, :]\n",
    "df['Target'] = 'X'\n",
    "df['Target_Num'] = 0\n",
    "majors = df[df['O_GROUP'] == 'major']['OCC_TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create string and numeric representations for major occupation titles\n",
    "df.loc[1:73, 'Target'] = majors[1]\n",
    "df.loc[1:73, 'Target_Num'] = 1\n",
    "df.loc[74:131, 'Target'] = majors[74]\n",
    "df.loc[74:131, 'Target_Num'] = 2\n",
    "df.loc[132:167, 'Target'] = majors[132]\n",
    "df.loc[132:167, 'Target_Num'] = 3\n",
    "df.loc[168:228, 'Target'] = majors[168]\n",
    "df.loc[168:228, 'Target_Num'] = 4\n",
    "df.loc[229:307, 'Target'] = majors[229]\n",
    "df.loc[229:307, 'Target_Num'] = 5\n",
    "df.loc[308:333, 'Target'] = majors[308]\n",
    "df.loc[308:333, 'Target_Num'] = 6\n",
    "df.loc[334:348, 'Target'] = majors[334]\n",
    "df.loc[334:348, 'Target_Num'] = 7\n",
    "df.loc[349:445, 'Target'] = majors[349]\n",
    "df.loc[349:445, 'Target_Num'] = 8\n",
    "df.loc[446:507, 'Target'] = majors[446]\n",
    "df.loc[446:507, 'Target_Num'] = 9\n",
    "df.loc[508:609, 'Target'] = majors[508]\n",
    "df.loc[508:609, 'Target_Num'] = 10\n",
    "df.loc[610:636, 'Target'] = majors[610]\n",
    "df.loc[610:636, 'Target_Num'] = 11\n",
    "df.loc[637:679, 'Target'] = majors[637]\n",
    "df.loc[637:679, 'Target_Num'] = 12\n",
    "df.loc[680:712, 'Target'] = majors[680]\n",
    "df.loc[680:712, 'Target_Num'] = 13\n",
    "df.loc[713:730, 'Target'] = majors[713]\n",
    "df.loc[713:730, 'Target_Num'] = 14\n",
    "df.loc[731:790, 'Target'] = majors[731]\n",
    "df.loc[731:790, 'Target_Num'] = 15\n",
    "df.loc[791:833, 'Target'] = majors[791]\n",
    "df.loc[791:833, 'Target_Num'] = 16\n",
    "df.loc[834:942, 'Target'] = majors[834]\n",
    "df.loc[834:942, 'Target_Num'] = 17\n",
    "df.loc[943:966, 'Target'] = majors[943]\n",
    "df.loc[943:966, 'Target_Num'] = 18\n",
    "df.loc[967:1069, 'Target'] = majors[967]\n",
    "df.loc[967:1069, 'Target_Num'] = 19\n",
    "df.loc[1070:1144, 'Target'] = majors[1070]\n",
    "df.loc[1070:1144, 'Target_Num'] = 20\n",
    "df.loc[1145:1311, 'Target'] = majors[1145]\n",
    "df.loc[1145:1311, 'Target_Num'] = 21\n",
    "df.loc[1312:1402, 'Target'] = majors[1312]\n",
    "df.loc[1312:1402, 'Target_Num'] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows containing '*'\n",
    "df = df[df.apply(lambda x: (~x.astype(str).str.contains('\\*', case=True, regex=True)))].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./../../data/01-modified-data/occupations_detailed_(employment_and_wage).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employment (by sex) and Wages BLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../../data/01-modified-data/occupations_detailed_(employment_and_wage).csv')\n",
    "df2 = pd.read_excel('../../data/00-raw-data/employment_(by_occupation_and_by_sex).xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(df1.iloc[:, [0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['OCC_TITLE', 'O_GROUP', 'TOT_EMP', 'A_MEAN', 'Target', 'Target_Num']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['OCC_TITLE'] = df1['OCC_TITLE'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.iloc[8:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns.values[0] = 'Occupation'\n",
    "df2.columns.values[1] = 'Total Employed'\n",
    "df2.columns.values[2] = 'Women (%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[pd.to_numeric(df2['Women (%)'], errors='coerce').notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Men (%)'] = 100 - df2.loc[:]['Women (%)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Occupation'] = df2['Occupation'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.merge(df2, how='inner', left_on='OCC_TITLE', right_on='Occupation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['O_GROUP'] == 'detailed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.iloc[:, [1,6]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./../../data/01-modified-data/occupations_detailed_(employment_by_sex_and_wage).csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea9dbe9f1ceea520258f7c79d3032f6041e6e0b09a8802a98b59f7606cb93a48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
