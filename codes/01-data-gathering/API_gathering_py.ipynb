{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering - Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import tweepy\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up API keys and TwitterAPI Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../01-data-gathering/twitterapiauth.txt'\n",
    "input_path = os.path.join(os.path.dirname(__file__), input_path)\n",
    "api = pd.read_csv(input_path, sep=\" \", header=None)\n",
    "\n",
    "consumer_key        = api.loc[0,1]\n",
    "consumer_secret     = api.loc[1,1]\n",
    "access_token        = api.loc[2,1]\n",
    "access_token_secret = api.loc[3,1]\n",
    "bearer_token        = api.loc[4,1]\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API()\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define needed functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_twitter function\n",
    "def search_twitter(max_results, query, tweet_fields, start_time, end_time, bearer_token):\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?max_results={}&query={}&start_time={}&end_time={}&{}\".format(\n",
    "        max_results, query, start_time, end_time, tweet_fields\n",
    "    )\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "    print(response.status_code)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "# pretty print function\n",
    "def pretty_print_json(input):\n",
    "    print(json.dumps(input, indent=4, sort_keys=True))\n",
    "    \n",
    "# gather the 100 tweets each over the last week. x CANNOT exceed 6\n",
    "def collect(x=6):\n",
    "    l = []\n",
    "    dtformat = '%Y-%m-%dT%H:%M:%SZ'\n",
    "    time = datetime.utcnow()\n",
    "    for i in range(1, x + 1):\n",
    "        start_time = time - timedelta(days=i + 1)\n",
    "        end_time = time - timedelta(days=i)\n",
    "        start_time, end_time = start_time.strftime(dtformat), end_time.strftime(dtformat)\n",
    "        json_response = search_twitter(max_results=max_results, query=query, tweet_fields=tweet_fields, start_time=start_time, end_time=end_time, bearer_token=bearer_token)\n",
    "        dictJson = json.loads(json.dumps(json_response))\n",
    "        l.append(dictJson)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters for search_twitter() and collect() functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results = 100\n",
    "tweet_fields = \"tweet.fields=text,lang\"\n",
    "\n",
    "# search for commonly associated words with gender equality\n",
    "# e.g. wagegap, earningsgap, feminism, men's rights, women's rights, MGTOW\n",
    "query = \"%23wagegap%20OR%20%23earningsgap%20OR%20%23feminism%20OR%20%23men%27srights%20OR%20%23women%27srights%20OR%20%23MGTOW%20\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create API call and export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictList = collect()\n",
    "\n",
    "tweets_list = []\n",
    "\n",
    "for tweets in dictList:\n",
    "    for tweet in tweets['data']:\n",
    "        if tweet['lang'] == 'en':\n",
    "            tweets_list.append(tweet['text'].split())\n",
    "\n",
    "words = [inner for outer in tweets_list for inner in outer]\n",
    "d = {}\n",
    "\n",
    "for word in words:\n",
    "    d[word] = d.get(word, 0) + 1\n",
    "\n",
    "# export to csv\n",
    "df = pd.DataFrame(d.items(), columns=['Word', 'Count'])\n",
    "pd.DataFrame.to_csv(df, \"Tweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66cb82efb67329302d3f747106a632c7db0601bc9483ecc21c622542c462cef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
