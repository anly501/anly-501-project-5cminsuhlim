<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>svm_classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="svm_classification_files/libs/clipboard/clipboard.min.js"></script>
<script src="svm_classification_files/libs/quarto-html/quarto.js"></script>
<script src="svm_classification_files/libs/quarto-html/popper.min.js"></script>
<script src="svm_classification_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="svm_classification_files/libs/quarto-html/anchor.min.js"></script>
<link href="svm_classification_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="svm_classification_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="svm_classification_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="svm_classification_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="svm_classification_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#classification-with-support-vector-machines" id="toc-classification-with-support-vector-machines" class="nav-link active" data-scroll-target="#classification-with-support-vector-machines">Classification with Support Vector Machines</a>
  <ul class="collapse">
  <li><a href="#methods" id="toc-methods" class="nav-link" data-scroll-target="#methods">Methods</a>
  <ul class="collapse">
  <li><a href="#imports" id="toc-imports" class="nav-link" data-scroll-target="#imports">Imports</a></li>
  <li><a href="#load-data" id="toc-load-data" class="nav-link" data-scroll-target="#load-data">Load Data</a></li>
  </ul></li>
  <li><a href="#feature-selection" id="toc-feature-selection" class="nav-link" data-scroll-target="#feature-selection">Feature Selection</a>
  <ul class="collapse">
  <li><a href="#re-format-data" id="toc-re-format-data" class="nav-link" data-scroll-target="#re-format-data">Re-format data</a></li>
  <li><a href="#vectorize" id="toc-vectorize" class="nav-link" data-scroll-target="#vectorize">Vectorize</a></li>
  </ul></li>
  <li><a href="#class-distribution" id="toc-class-distribution" class="nav-link" data-scroll-target="#class-distribution">Class Distribution</a>
  <ul class="collapse">
  <li><a href="#numerical-eda" id="toc-numerical-eda" class="nav-link" data-scroll-target="#numerical-eda">Numerical EDA</a></li>
  </ul></li>
  <li><a href="#baseline-random-classifier" id="toc-baseline-random-classifier" class="nav-link" data-scroll-target="#baseline-random-classifier">Baseline: Random Classifier</a>
  <ul class="collapse">
  <li><a href="#define-random-classifier-function" id="toc-define-random-classifier-function" class="nav-link" data-scroll-target="#define-random-classifier-function">Define Random Classifier Function</a></li>
  </ul></li>
  <li><a href="#feature-selection-cont." id="toc-feature-selection-cont." class="nav-link" data-scroll-target="#feature-selection-cont.">Feature Selection (cont.)</a>
  <ul class="collapse">
  <li><a href="#split-data-number-of-features" id="toc-split-data-number-of-features" class="nav-link" data-scroll-target="#split-data-number-of-features">Split Data (number of features)</a></li>
  <li><a href="#helper-functions" id="toc-helper-functions" class="nav-link" data-scroll-target="#helper-functions">Helper Functions</a></li>
  <li><a href="#linear-kernel-feature-selection" id="toc-linear-kernel-feature-selection" class="nav-link" data-scroll-target="#linear-kernel-feature-selection">Linear Kernel Feature Selection</a></li>
  <li><a href="#gaussian-kernel-feature-selection" id="toc-gaussian-kernel-feature-selection" class="nav-link" data-scroll-target="#gaussian-kernel-feature-selection">Gaussian Kernel Feature Selection</a></li>
  <li><a href="#sigmoid-kernel-feature-selection" id="toc-sigmoid-kernel-feature-selection" class="nav-link" data-scroll-target="#sigmoid-kernel-feature-selection">Sigmoid Kernel Feature Selection</a></li>
  <li><a href="#polynomial-kernel-feature-selection" id="toc-polynomial-kernel-feature-selection" class="nav-link" data-scroll-target="#polynomial-kernel-feature-selection">Polynomial Kernel Feature Selection</a></li>
  <li><a href="#split-data-model-selection" id="toc-split-data-model-selection" class="nav-link" data-scroll-target="#split-data-model-selection">Split Data (model selection)</a></li>
  </ul></li>
  <li><a href="#model-tuning" id="toc-model-tuning" class="nav-link" data-scroll-target="#model-tuning">Model Tuning</a>
  <ul class="collapse">
  <li><a href="#train-linear-kernel" id="toc-train-linear-kernel" class="nav-link" data-scroll-target="#train-linear-kernel">Train Linear Kernel</a></li>
  <li><a href="#check-the-results" id="toc-check-the-results" class="nav-link" data-scroll-target="#check-the-results">Check the Results</a></li>
  <li><a href="#train-gaussian-kernel" id="toc-train-gaussian-kernel" class="nav-link" data-scroll-target="#train-gaussian-kernel">Train Gaussian Kernel</a></li>
  <li><a href="#check-the-results-1" id="toc-check-the-results-1" class="nav-link" data-scroll-target="#check-the-results-1">Check the Results</a></li>
  <li><a href="#train-sigmoid-kernel" id="toc-train-sigmoid-kernel" class="nav-link" data-scroll-target="#train-sigmoid-kernel">Train Sigmoid Kernel</a></li>
  <li><a href="#check-the-results-2" id="toc-check-the-results-2" class="nav-link" data-scroll-target="#check-the-results-2">Check the Results</a></li>
  <li><a href="#polynomial-kernel-hyperparameter-tuning" id="toc-polynomial-kernel-hyperparameter-tuning" class="nav-link" data-scroll-target="#polynomial-kernel-hyperparameter-tuning">Polynomial Kernel Hyperparameter Tuning</a></li>
  <li><a href="#train-polynomial-kernel" id="toc-train-polynomial-kernel" class="nav-link" data-scroll-target="#train-polynomial-kernel">Train Polynomial Kernel</a></li>
  <li><a href="#check-the-results-3" id="toc-check-the-results-3" class="nav-link" data-scroll-target="#check-the-results-3">Check the Results</a></li>
  <li><a href="#comparing-models" id="toc-comparing-models" class="nav-link" data-scroll-target="#comparing-models">Comparing Models</a></li>
  <li><a href="#hyperparameter-tuning" id="toc-hyperparameter-tuning" class="nav-link" data-scroll-target="#hyperparameter-tuning">Hyperparameter Tuning</a></li>
  <li><a href="#train-optimal-model" id="toc-train-optimal-model" class="nav-link" data-scroll-target="#train-optimal-model">Train Optimal Model</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">



<section id="classification-with-support-vector-machines" class="level1">
<h1>Classification with Support Vector Machines</h1>
<section id="methods" class="level2">
<h2 class="anchored" data-anchor-id="methods">Methods</h2>
<p>For our analysis below, we will be using sentences gathered from various Wikipedia pages for searches that related to the keywords “Women’s rights” and “Men’s rights” to classify specific sentences with either of the two search terms.</p>
<section id="imports" class="level3">
<h3 class="anchored" data-anchor-id="imports">Imports</h3>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> sklearn</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> datasets</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> recall_score</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="load-data" class="level3">
<h3 class="anchored" data-anchor-id="load-data">Load Data</h3>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">'../../../data/00-raw-data/wiki-crawl-results.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="feature-selection" class="level2">
<h2 class="anchored" data-anchor-id="feature-selection">Feature Selection</h2>
<section id="re-format-data" class="level3">
<h3 class="anchored" data-anchor-id="re-format-data">Re-format data</h3>
<p>First, we conduct some preprocessing on the text data. We separate results from Wikipedia pages for “Women’s rights” and “Men’s rights” and vectorize the text results.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">#CONVERT FROM STRING LABELS TO INTEGERS </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>labels<span class="op">=</span>[]<span class="op">;</span> <span class="co">#y1=[]; y2=[]</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>y1<span class="op">=</span>[]</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> label <span class="kw">in</span> df[<span class="st">"label"</span>]:</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> label <span class="kw">not</span> <span class="kw">in</span> labels:</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        labels.append(label)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"index ="</span>,<span class="bu">len</span>(labels)<span class="op">-</span><span class="dv">1</span>,<span class="st">": label ="</span>,label)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(labels)):</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(label<span class="op">==</span>labels[i]):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            y1.append(i)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>y1<span class="op">=</span>np.array(y1)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># CONVERT DF TO LIST OF STRINGS </span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>corpus<span class="op">=</span>df[<span class="st">"text"</span>].to_list()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>y2<span class="op">=</span>df[<span class="st">"sentiment"</span>].to_numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>index = 0 : label = Women's rights
index = 1 : label = Men's rights</code></pre>
</div>
</div>
</section>
<section id="vectorize" class="level3">
<h3 class="anchored" data-anchor-id="vectorize">Vectorize</h3>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># INITIALIZE COUNT VECTORIZER</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># minDF = 0.01 means "ignore terms that appear in less than 1% of the documents". </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># minDF = 5 means "ignore terms that appear in less than 5 documents".</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>vectorizer<span class="op">=</span>CountVectorizer(min_df<span class="op">=</span><span class="fl">0.001</span>,max_features<span class="op">=</span><span class="dv">10000</span>,stop_words<span class="op">=</span><span class="st">"english"</span>)   </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co"># RUN COUNT VECTORIZER ON OUR COURPUS </span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>Xs  <span class="op">=</span>  vectorizer.fit_transform(corpus)   </span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>X<span class="op">=</span>np.array(Xs.todense())</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">#CONVERT TO ONE-HOT VECTORS</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>maxs<span class="op">=</span>np.<span class="bu">max</span>(X,axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>X<span class="op">=</span>np.ceil(X<span class="op">/</span>maxs)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>vocab0 <span class="op">=</span> vectorizer.vocabulary_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>After vectorizing our text data, we reorder our dataframe to sort the words in decreasing order based on its frequency and do some additional quality of life formatting changes.</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#swap keys and values (value --&gt; ley)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>vocab1 <span class="op">=</span> <span class="bu">dict</span>([(value, key) <span class="cf">for</span> key, value <span class="kw">in</span> vocab0.items()])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#RE-ORDER COLUMN SO IT IS SORTED FROM HIGH FREQ TERMS TO LOW </span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># https://stackoverflow.com/questions/60758625/sort-pandas-dataframe-by-sum-of-columns</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>df2<span class="op">=</span>pd.DataFrame(X)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> df2.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>df2<span class="op">=</span>df2[s.sort_values(ascending<span class="op">=</span><span class="va">False</span>).index[:]]</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># REMAP DICTIONARY TO CORRESPOND TO NEW COLUMN NUMBERS</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>i1<span class="op">=</span><span class="dv">0</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>vocab2<span class="op">=</span>{}</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i2 <span class="kw">in</span> <span class="bu">list</span>(df2.columns):</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(i2)</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    vocab2[i1]<span class="op">=</span>vocab1[<span class="bu">int</span>(i2)]</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    i1<span class="op">+=</span><span class="dv">1</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>df2.columns <span class="op">=</span> <span class="bu">range</span>(df2.columns.size)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>df2.to_numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
</div>
</section>
</section>
<section id="class-distribution" class="level2">
<h2 class="anchored" data-anchor-id="class-distribution">Class Distribution</h2>
<section id="numerical-eda" class="level3">
<h3 class="anchored" data-anchor-id="numerical-eda">Numerical EDA</h3>
<p>As shown in the output below, our target class is heavily imbalanced. Since this imbalance can skew the way the data is split into training and test sets, we will later stratify the data so the proportion of values in the training and test sets also reflect this imbalance.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DOUBLE CHECK </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x shape:"</span>, x.shape)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"y1 shape:"</span>, y1.shape)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.unique(y1, return_counts<span class="op">=</span><span class="va">True</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x shape: (420, 9792)
y1 shape: (420,)
(array([0, 1]), array([291, 129], dtype=int64))</code></pre>
</div>
</div>
</section>
</section>
<section id="baseline-random-classifier" class="level2">
<h2 class="anchored" data-anchor-id="baseline-random-classifier">Baseline: Random Classifier</h2>
<p>In order to have some baseline to compare our SVM’s performance, we defined a random classifier below.</p>
<section id="define-random-classifier-function" class="level3">
<h3 class="anchored" data-anchor-id="define-random-classifier-function">Define Random Classifier Function</h3>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_recall_fscore_support</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> random_classifier(y_data):</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    ypred<span class="op">=</span>[]<span class="op">;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    max_label<span class="op">=</span>np.<span class="bu">max</span>(y_data)<span class="op">;</span> <span class="co">#print(max_label)</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(y_data)):</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        ypred.append(<span class="bu">int</span>(np.floor((max_label<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>np.random.uniform(<span class="dv">0</span>,<span class="dv">1</span>))))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"-----RANDOM CLASSIFIER-----"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"count of prediction:"</span>,Counter(ypred).values()) <span class="co"># counts the elements' frequency</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"probability of prediction:"</span>,np.fromiter(Counter(ypred).values(), dtype<span class="op">=</span><span class="bu">float</span>)<span class="op">/</span><span class="bu">len</span>(y_data)) <span class="co"># counts the elements' frequency</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"accuracy"</span>,accuracy_score(y_data, ypred))</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"precision, recall, fscore,"</span>,precision_recall_fscore_support(y_data, ypred))</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>random_classifier(y1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>-----RANDOM CLASSIFIER-----
count of prediction: dict_values([239, 181])
probability of prediction: [0.56904762 0.43095238]
accuracy 0.5095238095238095
precision, recall, fscore, (array([0.73480663, 0.33891213]), array([0.45704467, 0.62790698]), array([0.56355932, 0.44021739]), array([291, 129], dtype=int64))</code></pre>
</div>
</div>
<p>Based on the output above, we can see that accuracy of the random classifier is around 0.5, which is around what we’d expect from randomly taking guesses for 2 target classes. We can also see that the precision, recall, and f-scores from the random classifier are around 0.7, 0.5, and 0.6, respectively.</p>
</section>
</section>
<section id="feature-selection-cont." class="level2">
<h2 class="anchored" data-anchor-id="feature-selection-cont.">Feature Selection (cont.)</h2>
<p>First, we split the text data. We split by index here so we have the same rows being used every time we run the code below. This is to remove noise created by full randomization with data splitting, which changes up what rows are used each time.</p>
<section id="split-data-number-of-features" class="level3">
<h3 class="anchored" data-anchor-id="split-data-number-of-features">Split Data (number of features)</h3>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>N<span class="op">=</span>X.shape[<span class="dv">0</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>l <span class="op">=</span> [<span class="op">*</span><span class="bu">range</span>(N)]     <span class="co"># indices</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>cut <span class="op">=</span> <span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> N) <span class="co">#80% of the list</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>random.shuffle(l)   <span class="co"># randomize</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>train_index <span class="op">=</span> l[:cut] <span class="co"># first 80% of shuffled list</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>test_index <span class="op">=</span> l[cut:] <span class="co"># last 20% of shuffled list</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_index[<span class="dv">0</span>:<span class="dv">10</span>])</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_index[<span class="dv">0</span>:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[4, 10, 36, 223, 23, 162, 16, 345, 246, 234]
[14, 144, 161, 224, 302, 212, 131, 276, 32, 265]</code></pre>
</div>
</div>
</section>
<section id="helper-functions" class="level3">
<h3 class="anchored" data-anchor-id="helper-functions">Helper Functions</h3>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">##UTILITY FUNCTION TO INITIALIZE RELEVANT ARRAYS</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> initialize_arrays():</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> num_features,train_accuracies</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> test_accuracies,train_time,eval_time</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    num_features<span class="op">=</span>[]</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    train_accuracies<span class="op">=</span>[]</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    test_accuracies<span class="op">=</span>[]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    train_time<span class="op">=</span>[]</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    eval_time<span class="op">=</span>[]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_SVC_model(X,Y,kernel<span class="op">=</span><span class="st">'linear'</span>,i_print<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i_print):</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(X.shape,Y.shape)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="bu">type</span>(X),<span class="bu">type</span>(Y))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#SPLIT</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    x_train<span class="op">=</span>X[train_index]</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    y_train<span class="op">=</span>Y[train_index].flatten()</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    x_test<span class="op">=</span>X[test_index]</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    y_test<span class="op">=</span>Y[test_index].flatten()</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># INITIALIZE MODEL </span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel<span class="op">=</span>kernel)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># TRAIN MODEL </span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.process_time()</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train,y_train)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    time_train<span class="op">=</span>time.process_time() <span class="op">-</span> start</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># LABEL PREDICTIONS FOR TRAINING AND </span><span class="al">TEST</span><span class="co"> SET </span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.process_time()</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>    time_eval<span class="op">=</span>time.process_time() <span class="op">-</span> start</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    acc_train<span class="op">=</span> accuracy_score(y_train, yp_train)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>    acc_test<span class="op">=</span> accuracy_score(y_test, yp_test)<span class="op">*</span><span class="dv">100</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(i_print):</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(acc_train,acc_test,time_train,time_eval)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (acc_train,acc_test,time_train,time_eval)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DEFINE SEARCH FUNCTION</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> partial_grid_search(num_runs, min_index, max_index):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, num_runs<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># SUBSET FEATURES </span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        upper_index<span class="op">=</span>min_index<span class="op">+</span>i<span class="op">*</span><span class="bu">int</span>((max_index<span class="op">-</span>min_index)<span class="op">/</span>num_runs)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>        xtmp<span class="op">=</span>x[:,<span class="dv">0</span>:upper_index]</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">#TRAIN </span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        (acc_train,acc_test,time_train,time_eval)<span class="op">=</span>train_SVC_model(xtmp,y1,i_print<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(i<span class="op">%</span><span class="dv">5</span><span class="op">==</span><span class="dv">0</span>):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(i,upper_index,xtmp.shape[<span class="dv">1</span>],acc_train,acc_test)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">#RECORD </span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        num_features.append(xtmp.shape[<span class="dv">1</span>])</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>        train_accuracies.append(acc_train)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        test_accuracies.append(acc_test)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>        train_time.append(time_train)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        eval_time.append(time_eval)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">#UTILITY FUNCTION TO PLOT RESULTS</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_results():</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#PLOT-1</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    plt.plot(num_features,train_accuracies,<span class="st">'-or'</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    plt.plot(num_features,test_accuracies,<span class="st">'-ob'</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Number of features'</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'ACCURACY: Training (blue) and Test (red)'</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    plt.show()<span class="op">;</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># #PLOT-2</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    plt.plot(num_features,train_time,<span class="st">'-or'</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    plt.plot(num_features,eval_time,<span class="st">'-ob'</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Number of features'</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Runtime: training time (red) and evaluation time(blue)'</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    plt.show()<span class="op">;</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># #PLOT-3</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.array(test_accuracies),train_time,<span class="st">'-or'</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    plt.plot(np.array(test_accuracies),eval_time,<span class="st">'-ob'</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'test_accuracies'</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Runtime: training time (red) and evaluation time (blue)'</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    plt.show()<span class="op">;</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># #PLOT-3</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    plt.plot(num_features,np.array(train_accuracies)<span class="op">-</span>np.array(test_accuracies),<span class="st">'-or'</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Number of features'</span>)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'train_accuracies-test_accuracies'</span>)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    plt.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we perform feature selection for the various SVM kernels, using the default SVM parameters (which will be optimized later on as well). The main metrics for determining the optimal number of features that will be used for analysis are the training and test accuracies and runtimes for varying number of features.</p>
</section>
<section id="linear-kernel-feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="linear-kernel-feature-selection">Linear Kernel Feature Selection</h3>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">#linear</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>(acc_train,acc_test,time_train,time_eval)<span class="op">=</span>train_SVC_model(x,y1,<span class="st">'linear'</span>,i_print<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>initialize_arrays()</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># DENSE SEARCH (SMALL NUMBER OF FEATURES (FAST))</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">100</span>, min_index<span class="op">=</span><span class="dv">0</span>, max_index<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co"># SPARSE SEARCH (LARGE NUMBER OF FEATURES (SLOWER))</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">20</span>, min_index<span class="op">=</span><span class="dv">1000</span>, max_index<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>plot_results()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(420, 9792) (420,)
&lt;class 'numpy.ndarray'&gt; &lt;class 'numpy.ndarray'&gt;</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>97.61904761904762 82.14285714285714 0.71875 0.65625
5 50 50 86.01190476190477 75.0
10 100 100 93.45238095238095 75.0
15 150 150 96.13095238095238 72.61904761904762</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>20 200 200 97.02380952380952 83.33333333333334
25 250 250 97.02380952380952 83.33333333333334
30 300 300 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>35 350 350 97.61904761904762 79.76190476190477
40 400 400 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>45 450 450 97.61904761904762 79.76190476190477
50 500 500 97.61904761904762 80.95238095238095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>55 550 550 97.61904761904762 79.76190476190477
60 600 600 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>65 650 650 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>70 700 700 97.61904761904762 76.19047619047619</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>75 750 750 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>80 800 800 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>85 850 850 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>90 900 900 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>95 950 950 97.61904761904762 80.95238095238095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>100 1000 1000 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>5 3250 3250 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10 5500 5500 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>15 7750 7750 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>20 10000 9792 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-14-output-19.png" width="592" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-14-output-20.png" width="596" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-14-output-21.png" width="589" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-14-output-22.png" width="605" height="429"></p>
</div>
</div>
<p>Based on the plots above, the optimal number of features for the linear kernel seems to be around 3000. This range of features is where the test set accuracy seems to plateau, and it is also the point directly before runtime begins to increase significantly.</p>
</section>
<section id="gaussian-kernel-feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-kernel-feature-selection">Gaussian Kernel Feature Selection</h3>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">#gaussian</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>(acc_train,acc_test,time_train,time_eval)<span class="op">=</span>train_SVC_model(x,y1,<span class="st">'rbf'</span>,i_print<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>initialize_arrays()</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># DENSE SEARCH (SMALL NUMBER OF FEATURES (FAST))</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">100</span>, min_index<span class="op">=</span><span class="dv">0</span>, max_index<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co"># SPARSE SEARCH (LARGE NUMBER OF FEATURES (SLOWER))</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">20</span>, min_index<span class="op">=</span><span class="dv">1000</span>, max_index<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>plot_results()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(420, 9792) (420,)
&lt;class 'numpy.ndarray'&gt; &lt;class 'numpy.ndarray'&gt;</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>97.61904761904762 69.04761904761905 0.640625 1.421875
5 50 50 86.01190476190477 75.0
10 100 100 93.45238095238095 75.0
15 150 150 96.13095238095238 72.61904761904762</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>20 200 200 97.02380952380952 83.33333333333334
25 250 250 97.02380952380952 83.33333333333334
30 300 300 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>35 350 350 97.61904761904762 79.76190476190477
40 400 400 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>45 450 450 97.61904761904762 79.76190476190477
50 500 500 97.61904761904762 80.95238095238095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>55 550 550 97.61904761904762 79.76190476190477
60 600 600</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code> 97.61904761904762 78.57142857142857
65 650 650 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>70 700 700 97.61904761904762 76.19047619047619</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>75 750 750 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>80 800 800 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>85 850 850 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>90 900 900 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>95 950 950 97.61904761904762 80.95238095238095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>100 1000 1000 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>5 3250 3250 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10 5500 5500 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>15 7750 7750 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>20 10000 9792 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-15-output-19.png" width="592" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-15-output-20.png" width="596" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-15-output-21.png" width="589" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-15-output-22.png" width="605" height="429"></p>
</div>
</div>
<p>Based on the plots above, the optimal number of features for the gaussian kernel seems to be around 3000. This range of features is where the test set accuracy seems to plateau, and it is also the point directly before runtime begins to increase significantly.</p>
</section>
<section id="sigmoid-kernel-feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="sigmoid-kernel-feature-selection">Sigmoid Kernel Feature Selection</h3>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co">#sigmoid</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>(acc_train,acc_test,time_train,time_eval)<span class="op">=</span>train_SVC_model(x,y1,<span class="st">'sigmoid'</span>,i_print<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>initialize_arrays()</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a><span class="co"># DENSE SEARCH (SMALL NUMBER OF FEATURES (FAST))</span></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">100</span>, min_index<span class="op">=</span><span class="dv">0</span>, max_index<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a><span class="co"># SPARSE SEARCH (LARGE NUMBER OF FEATURES (SLOWER))</span></span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">20</span>, min_index<span class="op">=</span><span class="dv">1000</span>, max_index<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>plot_results()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(420, 9792) (420,)
&lt;class 'numpy.ndarray'&gt; &lt;class 'numpy.ndarray'&gt;</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>94.64285714285714 78.57142857142857 0.5625 0.59375
5 50 50 86.01190476190477 75.0
10 100 100 93.45238095238095 75.0
15 150 150 96.13095238095238 72.61904761904762</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>20 200 200 97.02380952380952 83.33333333333334
25 250 250 97.02380952380952 83.33333333333334
30 300 300 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>35 350 350 97.61904761904762 79.76190476190477
40 400 400 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>45 450 450 97.61904761904762 79.76190476190477
50 500 500 97.61904761904762 80.95238095238095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>55 550 550 97.61904761904762 79.76190476190477
60 600 600 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>65 650 650 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>70 700 700 97.61904761904762 76.19047619047619</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>75 750 750 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>80 800 800 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>85 850 850 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>90 900 900 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>95 950 950 97.61904761904762 80.95238095238095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>100 1000 1000 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>5 3250 3250 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10 5500 5500 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>15 7750 7750 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>20 10000 9792 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-16-output-19.png" width="592" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-16-output-20.png" width="596" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-16-output-21.png" width="589" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-16-output-22.png" width="605" height="429"></p>
</div>
</div>
<p>Based on the plots above, the optimal number of features for the sigmoid kernel seems to be around 3000. This range of features is where the test set accuracy seems to plateau, and it is also the point directly before runtime begins to increase significantly.</p>
</section>
<section id="polynomial-kernel-feature-selection" class="level3">
<h3 class="anchored" data-anchor-id="polynomial-kernel-feature-selection">Polynomial Kernel Feature Selection</h3>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co">#polynomial</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>(acc_train,acc_test,time_train,time_eval)<span class="op">=</span>train_SVC_model(x,y1,<span class="st">'poly'</span>,i_print<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>initialize_arrays()</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="co"># DENSE SEARCH (SMALL NUMBER OF FEATURES (FAST))</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">100</span>, min_index<span class="op">=</span><span class="dv">0</span>, max_index<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a><span class="co"># SPARSE SEARCH (LARGE NUMBER OF FEATURES (SLOWER))</span></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a>partial_grid_search(num_runs<span class="op">=</span><span class="dv">20</span>, min_index<span class="op">=</span><span class="dv">1000</span>, max_index<span class="op">=</span><span class="dv">10000</span>)</span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a>plot_results()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(420, 9792) (420,)
&lt;class 'numpy.ndarray'&gt; &lt;class 'numpy.ndarray'&gt;</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>86.30952380952381 65.47619047619048 0.65625 0.875
5 50 50 86.01190476190477 75.0
10 100 100 93.45238095238095 75.0
15 150 150 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>96.13095238095238 72.61904761904762
20 200 200 97.02380952380952 83.33333333333334
25 250 250 97.02380952380952 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>30 300 300 97.61904761904762 79.76190476190477
35 350 350 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>40 400 400 97.61904761904762 79.76190476190477
45 450 450 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>50 500 500 97.61904761904762 80.95238095238095
55 550 550 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>60 600 600 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>65 650 650 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>70 700 700 97.61904761904762 76.19047619047619</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>75 750 750 97.61904761904762 78.57142857142857</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>80 800 800 97.61904761904762 79.76190476190477</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>85 850 850 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>90 900 900 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>95 950 950 97.61904761904762 80.95238095238095</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>100 1000 1000 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>5 3250 3250 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>10 5500 5500 97.61904761904762 83.33333333333334</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>15 7750 7750 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>20 10000 9792 97.61904761904762 82.14285714285714</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-17-output-20.png" width="592" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-17-output-21.png" width="596" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-17-output-22.png" width="589" height="429"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-17-output-23.png" width="605" height="429"></p>
</div>
</div>
<p>Based on the plots above, the optimal number of features for the polynomial kernel seems to be around 3000. This range of features is where the test set accuracy seems to plateau, and it is also the point directly before runtime begins to increase significantly.</p>
</section>
<section id="split-data-model-selection" class="level3">
<h3 class="anchored" data-anchor-id="split-data-model-selection">Split Data (model selection)</h3>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PARTITION THE DATASET INTO TRAINING AND </span><span class="al">TEST</span><span class="co"> SETS</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>test_ratio<span class="op">=</span><span class="fl">0.2</span></span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(X[:, :<span class="dv">3000</span>], y1, test_size<span class="op">=</span>test_ratio, random_state<span class="op">=</span><span class="dv">0</span>, stratify<span class="op">=</span>y1)</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>y_train<span class="op">=</span>y_train.flatten()</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>y_test<span class="op">=</span>y_test.flatten()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>accuracy_training_l <span class="op">=</span> []</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a>accuracy_test_l <span class="op">=</span> []</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="model-tuning" class="level2">
<h2 class="anchored" data-anchor-id="model-tuning">Model Tuning</h2>
<p>There are multiple algorithms, or kernels, used by SVMs in performing classification. We will perform classification using linear, Gaussian, Sigmoid, and polynomial kernels, compare their performance, and choose the best kernel for this task.</p>
<section id="train-linear-kernel" class="level3">
<h3 class="anchored" data-anchor-id="train-linear-kernel">Train Linear Kernel</h3>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'linear'</span>)</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(x_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="check-the-results" class="level3">
<h3 class="anchored" data-anchor-id="check-the-results">Check the Results</h3>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># USE THE MODEL TO MAKE PREDICTIONS FOR THE TRAINING AND </span><span class="al">TEST</span><span class="co"> SET </span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>accuracy_training_l.append(accuracy_score(y_train, yp_train))</span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a>accuracy_test_l.append(accuracy_score(y_test, yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GENERATES A CONFUSION MATRIX PLOT AND PRINTS MODEL PERFORMANCE METRICS</span></span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> confusion_plot(y_data, y_pred):    </span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>    cm <span class="op">=</span> confusion_matrix(y_data, y_pred)</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a>    disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm)</span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>    disp.plot()</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'ACCURACY:'</span>, accuracy_score(y_data, y_pred))</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'RECALL:'</span>, recall_score(y_data, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'PRECISION:'</span>, precision_score(y_data, y_pred, average<span class="op">=</span><span class="st">'weighted'</span>))</span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-14"><a href="#cb99-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TRAINING (Linear)------"</span>)</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_train,yp_train)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TEST (Linear)------"</span>)</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_test,yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>------TRAINING (Linear)------
ACCURACY: 0.9732142857142857
RECALL: 0.9732142857142857
PRECISION: 0.9746372543385817</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-23-output-2.png" width="504" height="434"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>------TEST (Linear)------
ACCURACY: 0.6904761904761905
RECALL: 0.6904761904761905
PRECISION: 0.6726190476190477</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-23-output-4.png" width="496" height="429"></p>
</div>
</div>
<p>The linear kernel resulted in training accuracy, recall, and precision scores of 0.97 and test accuracy, recall, and precision scores of 0.70. This suggests a noticeable degree of overfitting.</p>
</section>
<section id="train-gaussian-kernel" class="level3">
<h3 class="anchored" data-anchor-id="train-gaussian-kernel">Train Gaussian Kernel</h3>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'rbf'</span>)</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(x_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="check-the-results-1" class="level3">
<h3 class="anchored" data-anchor-id="check-the-results-1">Check the Results</h3>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="co"># USE THE MODEL TO MAKE PREDICTIONS FOR THE TRAINING AND </span><span class="al">TEST</span><span class="co"> SET </span></span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>accuracy_training_l.append(accuracy_score(y_train, yp_train))</span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>accuracy_test_l.append(accuracy_score(y_test, yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TRAINING (Gaussian)------"</span>)</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_train,yp_train)</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TEST (Gaussian)------"</span>)</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_test,yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>------TRAINING (Gaussian)------
ACCURACY: 0.9672619047619048
RECALL: 0.9672619047619048
PRECISION: 0.9676962479003086</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-26-output-2.png" width="504" height="433"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>------TEST (Gaussian)------
ACCURACY: 0.6904761904761905
RECALL: 0.6904761904761905
PRECISION: 0.6347270615563299</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-26-output-4.png" width="496" height="429"></p>
</div>
</div>
<p>The Gaussian kernel resulted in training accuracy, recall, and precision scores of around 0.97 and test accuracy and recall scores of around 0.69 and precision score of around 0.63. This suggests a higher degree of overfitting than the linear kernel with worse accuracy.</p>
</section>
<section id="train-sigmoid-kernel" class="level3">
<h3 class="anchored" data-anchor-id="train-sigmoid-kernel">Train Sigmoid Kernel</h3>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'sigmoid'</span>)</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(x_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="check-the-results-2" class="level3">
<h3 class="anchored" data-anchor-id="check-the-results-2">Check the Results</h3>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="co"># USE THE MODEL TO MAKE PREDICTIONS FOR THE TRAINING AND </span><span class="al">TEST</span><span class="co"> SET </span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a>accuracy_training_l.append(accuracy_score(y_train, yp_train))</span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>accuracy_test_l.append(accuracy_score(y_test, yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb110"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TRAINING (Sigmoid)------"</span>)</span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_train,yp_train)</span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TEST (Sigmoid)------"</span>)</span>
<span id="cb110-4"><a href="#cb110-4" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_test,yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>------TRAINING (Sigmoid)------
ACCURACY: 0.8601190476190477
RECALL: 0.8601190476190477
PRECISION: 0.8799707770729229</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-29-output-2.png" width="504" height="429"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>------TEST (Sigmoid)------
ACCURACY: 0.7142857142857143
RECALL: 0.7142857142857143
PRECISION: 0.6931390977443609</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-29-output-4.png" width="496" height="429"></p>
</div>
</div>
<p>The Sigmoid kernel resulted in training accuracy, recall, and precision scores of around 0.86 and test accuracy and recall scores of about 0.71, and a precision score of around 0.7. This suggests a noticeable degree of overfitting but better performance than the previous Gaussian kernel.</p>
</section>
<section id="polynomial-kernel-hyperparameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="polynomial-kernel-hyperparameter-tuning">Polynomial Kernel Hyperparameter Tuning</h3>
<p>For the polynomial kernel, it is necessary to determine the degree of the polynomial. As such, we compare the accuracy for the training and test sets based on polynomial degrees ranging from 1 to 10. As the graph below shows, the best performance for both the training and test sets appears to be a polynomial degree of 1.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a>accuracies_train <span class="op">=</span> []</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>accuracies_test <span class="op">=</span> []</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>numbers <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> numbers:</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">'poly'</span>, degree <span class="op">=</span> i)</span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train, y_train)</span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>    yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>    yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>    cm_train <span class="op">=</span> confusion_matrix(y_train, yp_train)</span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>    ac_train <span class="op">=</span> accuracy_score(y_train, yp_train)</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>    cm_test <span class="op">=</span> confusion_matrix(y_test, yp_test)</span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a>    ac_test <span class="op">=</span> accuracy_score(y_test, yp_test)</span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'degree'</span>, <span class="st">': '</span>, <span class="st">'training acc'</span> , <span class="st">','</span>, <span class="st">'test acc'</span>)</span>
<span id="cb113-19"><a href="#cb113-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(i, <span class="st">": "</span>, ac_train, <span class="st">','</span>, ac_test)</span>
<span id="cb113-20"><a href="#cb113-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb113-21"><a href="#cb113-21" aria-hidden="true" tabindex="-1"></a>    accuracies_train.append(ac_train)</span>
<span id="cb113-22"><a href="#cb113-22" aria-hidden="true" tabindex="-1"></a>    accuracies_test.append(ac_test)</span>
<span id="cb113-23"><a href="#cb113-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb113-24"><a href="#cb113-24" aria-hidden="true" tabindex="-1"></a>plt.plot(numbers, accuracies_train, linewidth<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb113-25"><a href="#cb113-25" aria-hidden="true" tabindex="-1"></a>plt.scatter(numbers, accuracies_train, c<span class="op">=</span><span class="st">'b'</span>)</span>
<span id="cb113-26"><a href="#cb113-26" aria-hidden="true" tabindex="-1"></a>plt.plot(numbers, accuracies_test, linewidth<span class="op">=</span><span class="dv">1</span>, color<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb113-27"><a href="#cb113-27" aria-hidden="true" tabindex="-1"></a>plt.scatter(numbers, accuracies_test, c<span class="op">=</span><span class="st">'r'</span>)</span>
<span id="cb113-28"><a href="#cb113-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Polynomial Degree"</span>)</span>
<span id="cb113-29"><a href="#cb113-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"ACCURACY: Training (blue) and Test (red)"</span>)</span>
<span id="cb113-30"><a href="#cb113-30" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'fivethirtyeight'</span>)</span>
<span id="cb113-31"><a href="#cb113-31" aria-hidden="true" tabindex="-1"></a>plt.show()<span class="op">;</span></span>
<span id="cb113-32"><a href="#cb113-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-33"><a href="#cb113-33" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'default'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
1 :  0.9494047619047619 , 0.7380952380952381</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
2 :  0.8660714285714286 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
3 :  0.8392857142857143 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
4 :  0.8303571428571429 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
5 :  0.8184523809523809 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
6 :  0.8184523809523809 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
7 :  0.8184523809523809 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
8 :  0.8184523809523809 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
9 :  0.8095238095238095 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>degree :  training acc , test acc
10 :  0.8095238095238095 , 0.6904761904761905</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-30-output-11.png" width="597" height="429"></p>
</div>
</div>
</section>
<section id="train-polynomial-kernel" class="level3">
<h3 class="anchored" data-anchor-id="train-polynomial-kernel">Train Polynomial Kernel</h3>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC(kernel <span class="op">=</span> <span class="st">'poly'</span>, degree <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(x_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="check-the-results-3" class="level3">
<h3 class="anchored" data-anchor-id="check-the-results-3">Check the Results</h3>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># USE THE MODEL TO MAKE PREDICTIONS FOR THE TRAINING AND </span><span class="al">TEST</span><span class="co"> SET </span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> model.predict(x_test)</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a>accuracy_training_l.append(accuracy_score(y_train, yp_train))</span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a>accuracy_test_l.append(accuracy_score(y_test, yp_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TRAINING (Polynomial; degree=1)------"</span>)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_train,yp_train)</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TEST (Polynomial; degree=1)------"</span>)</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_test,yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>------TRAINING (Polynomial; degree=1)------
ACCURACY: 0.9494047619047619
RECALL: 0.9494047619047619
PRECISION: 0.949361359126984</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-33-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>------TEST (Polynomial; degree=1)------
ACCURACY: 0.7380952380952381
RECALL: 0.7380952380952381
PRECISION: 0.7298584298584297</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-33-output-4.png" class="img-fluid"></p>
</div>
</div>
<p>The Polynomial kernel resulted in training accuracy, recall, and precision scores of around 0.95 and test accuracy, recall, and precision scores of about 0.74. This suggests a noticeable degree of overfitting and a relatively similar performance to the Sigmoid kernel.</p>
</section>
<section id="comparing-models" class="level3">
<h3 class="anchored" data-anchor-id="comparing-models">Comparing Models</h3>
<p>To make comparison simpler, we create a plot for the accuracy scores of the four kernel types. The graph below shows that all four kernels have relatively similar degrees of training performance; however, the linear kernel appears to have the best test set accuracy.</p>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>kernel_types <span class="op">=</span> [<span class="st">'Linear'</span>, <span class="st">'Gaussian'</span>, <span class="st">'Sigmoid'</span>, <span class="st">'Polynomial'</span>]</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> {<span class="st">"Kernels"</span>: kernel_types, <span class="st">"Training Accuracy"</span>: accuracy_training_l, <span class="st">"Test Accuracy"</span>: accuracy_test_l}</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(d)</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.sort_values(by<span class="op">=</span>[<span class="st">"Test Accuracy"</span>], ascending<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> df.plot(kind<span class="op">=</span><span class="st">'bar'</span>, color<span class="op">=</span>[<span class="st">'b'</span>, <span class="st">'r'</span>])</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Kernel Types'</span>)</span>
<span id="cb130-4"><a href="#cb130-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Accuracy Scores for the Four Kernel Types'</span>)</span>
<span id="cb130-5"><a href="#cb130-5" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb130-6"><a href="#cb130-6" aria-hidden="true" tabindex="-1"></a>ax.set_xticklabels(df[<span class="st">'Kernels'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="148">
<pre><code>[Text(0, 0, 'Polynomial'),
 Text(1, 0, 'Sigmoid'),
 Text(2, 0, 'Linear'),
 Text(3, 0, 'Gaussian')]</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-35-output-2.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="hyperparameter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="hyperparameter-tuning">Hyperparameter Tuning</h3>
<p>Now, to find the best margin (C) for the linear kernel, we perform a grid search.</p>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="co"># defining parameter range</span></span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {<span class="st">'C'</span>: [<span class="dv">2</span><span class="op">**-</span><span class="dv">7</span>, <span class="dv">2</span><span class="op">**-</span><span class="dv">6</span>, <span class="dv">2</span><span class="op">**-</span><span class="dv">5</span>, <span class="dv">2</span><span class="op">**-</span><span class="dv">4</span>, <span class="dv">2</span><span class="op">**-</span><span class="dv">3</span>, <span class="dv">2</span><span class="op">**-</span><span class="dv">2</span>, <span class="dv">2</span><span class="op">**-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">1</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">2</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">3</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">4</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">5</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">6</span>, <span class="dv">2</span><span class="op">**</span><span class="dv">7</span>], </span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a>              <span class="st">'kernel'</span>: [<span class="st">'linear'</span>]} </span>
<span id="cb132-6"><a href="#cb132-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb132-7"><a href="#cb132-7" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(SVC(), param_grid, refit <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb132-8"><a href="#cb132-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb132-9"><a href="#cb132-9" aria-hidden="true" tabindex="-1"></a><span class="co"># fitting the model for grid search</span></span>
<span id="cb132-10"><a href="#cb132-10" aria-hidden="true" tabindex="-1"></a>grid.fit(x_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="149">
<pre><code>GridSearchCV(estimator=SVC(),
             param_grid={'C': [0.0078125, 0.015625, 0.03125, 0.0625, 0.125,
                               0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128],
                         'kernel': ['linear']})</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="co"># print best parameter after tuning</span></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(grid.best_params_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'C': 0.125, 'kernel': 'linear'}</code></pre>
</div>
</div>
</section>
<section id="train-optimal-model" class="level3">
<h3 class="anchored" data-anchor-id="train-optimal-model">Train Optimal Model</h3>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC(kernel<span class="op">=</span>grid.best_params_[<span class="st">'kernel'</span>], C<span class="op">=</span>grid.best_params_[<span class="st">'C'</span>])</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> model.fit(x_train, y_train)</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>yp_train <span class="op">=</span> model.predict(x_train)</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>yp_test <span class="op">=</span> model.predict(x_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TRAINING------"</span>)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_train,yp_train)</span>
<span id="cb137-3"><a href="#cb137-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"------TEST------"</span>)</span>
<span id="cb137-4"><a href="#cb137-4" aria-hidden="true" tabindex="-1"></a>confusion_plot(y_test,yp_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>------TRAINING------
ACCURACY: 0.9732142857142857
RECALL: 0.9732142857142857
PRECISION: 0.9746372543385817</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-39-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>------TEST------
ACCURACY: 0.6785714285714286
RECALL: 0.6785714285714286
PRECISION: 0.6565066512434934</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="svm_classification_files/figure-html/cell-39-output-4.png" class="img-fluid"></p>
</div>
</div>
<p>The confusion matrices for all four kernal types show marginally better performance for accuracy, recall, and precision scores for both the training and test sets compared to the performance of the baseline random classifier. Among these kernels, we also determined that the linear kernel outperformed the other three in terms of accuracy, recall, and precision scores for both the training and test sets; however, based on the results from the above confusion matrix, it still appears that the “optimal” hyperparameters still result in a noticeable degree of overfitting.</p>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>