<!DOCTYPE html>
<html lang="en">
    <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Clustering</title>
            <link rel="stylesheet" href="../../styles.css">
            <link href='https://fonts.googleapis.com/css?family=Castoro' rel='stylesheet'>
            <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
            <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    </head>
<body style="background-color:lightblue">
    <!-- banner -->
    <div>
        <img src="../../images/banner.jpg" class="banner"/>
    </div>

    <!-- navbar -->
    <nav class="navbar navbar-expand-lg fixed-top navbarScroll">
        <div class="container">
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="../../index.html">About</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/anly501/anly-501-project-5cminsuhlim" target="_blank">Code</a>
                    </li>
                    <!-- might need to change this in the future -->
                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/anly501/anly-501-project-5cminsuhlim/tree/main/data" target="_blank">Data</a>
                    </li>
                    <!--  -->
                    <li class="nav-item">
                        <a class="nav-link" href="../introduction.html">Introduction</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../datagathering/datagathering.html">Data Gathering</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../datacleaning/datacleaning.html">Data Cleaning</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../exploringdata/exploringdata.html">Exploring Data</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../clustering/clustering.html">Clustering</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../armandnetworking/armandnetworking.html">ARM and Networking</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../decisiontrees/decisiontrees.html">Decision Trees</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../naivebayes/naivebayes.html">Naive Bayes</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../svm/svm.html">SVM</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../randomforests/randomforests.html">Random Forests</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="../conclusions.html">Conclusions</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- clustering section-->
    <section id="clustering">
        <div class="container">
            <h1 class="text-center">Clustering</h1>

            <div class="row">
                <h2>Introduction</h2>
                <div>
                    <p>
                        The data set that will be used for clustering analysis is from the Bureau of Labor Statistics. This data set is a combined data set of employment and wages based on occupation (that was used in the <a href="../decisiontrees/decisiontrees.html">Decision Tree</a> and <a href="../randomforests/randomforests.html">Random Forest</a> classification sections) and employment based on occupation by sex. Our goal is to see how different occupations group up (or "cluster") based on different features. Specifically, the features that we will use is the total employment, average annual mean, and the sex proportions in each occupation (i.e. what percentage of the total employees in a specific occupation is men or women). For the specific code that achieved this data set, please refer to the <a href="../datacleaning/datacleaning.html">data cleaning section</a>.
                    </p>
                </div> 
    
                <h2>Theory</h2>
                <div>
                    <p>
                        Clustering is an example of an unsupervised machine learning algorithm attempts to discover if the data forms "clusters," and as the name suggests, clustering attempts to group similar data points in a data set together. This is especially handy when there are no known relationships in the data; however, even if the data already has corresponding labels, using the algorithm may reveal new clusters, which suggests that there may be unknown groups in the data that aren't captured in the pre-existing labels (which will be especially relevant for our data set, since it already has associated labels).
                    </p>

                    <p>
                        There are multiple clustering methods. The first is K-means clustering, which attempts to split the data into "K" clusters around a centroid (or the center of a cluster). The K-means algorithm focuses on minimizing the differences within a cluster while maximizing the differences between clusters. Another algorithm is Density-Based Spatial Clustering of Applications with Noise (DBSCAN), which clusters based on how closely together points are located (hence "density"). As such, this algorithm groups highly dense (closely packed) points together separate from outliers that lie in sparsely dense areas. Lastly, hierarchical clustering works by grouping the data points to produce nested clusters, represented as trees. This method can either take a top-down (Division) or bottom-up (Agglomerative) approach. The former starts with one big cluster of all the data points, which is broken down into smaller and smaller clusters, while the latter does the opposite (i.e. start with individual data points and build up into clusters).
                    </p>
                    
                    <p>
                        The aforementioned algorithms all mention grouping the data points into clusters. Naturally, this leads us onto our next point of finding out what actually is the optimal number of clusters. The first is the Elbow Method, which finds the corresponding inertias for a varying number of clusters. As the number of clusters increase, the inertia also decreases, so it is our job to decide the best cluster-to-inertia trade-off point (i.e. attempt to minimize both inertia and the number of clusters). An alternative is the Silhouette Method, which shows how distant a cluster is from other clusters. The silhouette coefficients range from -1 to 1, with -1 indicating bad clustering (i.e. a data point may have been assigned to the wrong cluster), 0 indicating clusters being very close to each other, and 1 indicating clusters that are far from each other.
                    </p>
                </div>
    
                <h2><a target="_blank" href="./clustering_methods.html" target="_blank">Methods</a></h2>
    
                <h2>Results</h2>
                <div>
                    <p>
                        Based on the final results for the three methods, the optimal number of clusters for DBSCAN, K-Means, and Hierarchical were 2, 3, and 4, respectively. Based on the silhouette coefficients across the three clustering algorithms, K-Means performed the best with the highest silhouette coefficient of 0.466, followed by Hierarchical with a coefficient of 0.435, and then DBSCAN with a coefficient of 0.340. In terms of setting up the models and the respective visualizations, K-Means was by far the most straightforward, followed by Hierarchical, and then DBSCAN. Interestingly, despite the ease of set up, this is the exact order of the silhouette coefficients as well.
                    </p>

                    <p>
                        None of the algorithms were able to completely accurately create optimal cluster predictions that coincided with the "Target" values we had in the data set; nonetheless, this reveals some new insights regarding our data. Firstly, the clustering results, especially the results from K-Means and Hierarchical clustering, seems to suggest that there are largely 3 or 4 major industries that  most occupations fall under. Secondly, based on the results from DBSCAN, it seems that most jobs, when clustered based on total employment, annual mean wages, and female participation, cluster together.
                    </p>
                </div>

                <h2>Conclusions</h2>
                <div>
                    <p>
                        The data with which the clustering was conducted is heavily imbalanced. Occupation categories (labeled as "Target" in the data set) ranged from having a single occupation in a larger category all the way up to 35 occupations. Hence, model improvements definitely could be seen if we had a more balanced data set. Nonetheless, our clustering results reveal some new insights regarding our data. Upon closer inspection of our original data set (from the "Numerical EDA" section in the <a target="_blank" href="./clustering_methods.html" target="_blank">Methods</a> section) in tandem with our clustering results, these industries seem to be Service, Labor, Engineering, and Management.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <script src="../../script.js"></script>
</body>
</html>